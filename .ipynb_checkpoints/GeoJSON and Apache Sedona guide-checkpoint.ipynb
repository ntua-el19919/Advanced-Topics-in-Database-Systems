{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b9512f",
   "metadata": {},
   "source": [
    "# Using GeoJSON - Apache Sedona in PySpark\n",
    "This notebook will demonstrate how you can use Apache Sedona in PySpark to perform geoanalytical queries. This development environment has been set up using version 1.6.1 of Apache Sedona.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5285f7cd-313c-44e6-984b-1af08a153890",
   "metadata": {},
   "source": [
    "## Reading GeoJSON from S3\n",
    "The first code cell reads the geojson file you will be asked to process in the semester project from S3 and prints its schema. Use this code to load it into Spark and access its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16e76fff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>228</td><td>application_1732639283265_0197</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_0197/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-166.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_0197_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- BG10: string (nullable = true)\n",
      " |-- BG10FIP10: string (nullable = true)\n",
      " |-- BG12: string (nullable = true)\n",
      " |-- CB10: string (nullable = true)\n",
      " |-- CEN_FIP13: string (nullable = true)\n",
      " |-- CITY: string (nullable = true)\n",
      " |-- CITYCOM: string (nullable = true)\n",
      " |-- COMM: string (nullable = true)\n",
      " |-- CT10: string (nullable = true)\n",
      " |-- CT12: string (nullable = true)\n",
      " |-- CTCB10: string (nullable = true)\n",
      " |-- HD_2012: long (nullable = true)\n",
      " |-- HD_NAME: string (nullable = true)\n",
      " |-- HOUSING10: long (nullable = true)\n",
      " |-- LA_FIP10: string (nullable = true)\n",
      " |-- OBJECTID: long (nullable = true)\n",
      " |-- POP_2010: long (nullable = true)\n",
      " |-- PUMA10: string (nullable = true)\n",
      " |-- SPA_2012: long (nullable = true)\n",
      " |-- SPA_NAME: string (nullable = true)\n",
      " |-- SUP_DIST: string (nullable = true)\n",
      " |-- SUP_LABEL: string (nullable = true)\n",
      " |-- ShapeSTArea: double (nullable = true)\n",
      " |-- ShapeSTLength: double (nullable = true)\n",
      " |-- ZCTA10: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)"
     ]
    }
   ],
   "source": [
    "from sedona.spark import *\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"GeoJSON read\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Create sedona context\n",
    "sedona = SedonaContext.create(spark)\n",
    "# Read the file from s3\n",
    "geojson_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson\"\n",
    "blocks_df = sedona.read.format(\"geojson\") \\\n",
    "            .option(\"multiLine\", \"true\").load(geojson_path) \\\n",
    "            .selectExpr(\"explode(features) as features\") \\\n",
    "            .select(\"features.*\")\n",
    "# Formatting magic\n",
    "flattened_df = blocks_df.select( \\\n",
    "                [col(f\"properties.{col_name}\").alias(col_name) for col_name in \\\n",
    "                blocks_df.schema[\"properties\"].dataType.fieldNames()] + [\"geometry\"]) \\\n",
    "            .drop(\"properties\") \\\n",
    "            .drop(\"type\")\n",
    "# Print schema\n",
    "flattened_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78160d7b-5025-42f3-98b9-448b3baf6773",
   "metadata": {},
   "source": [
    "## Creation of `geometry` type columns from (lat, long) coordinates using `ST_Point`\n",
    "The next cell block demonstrates how you can create a `geometry` type column from a coordinates pair. Sedona can execute geoanalytics queries on `geometry` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea030fae-9688-49fb-86f8-137fb3bee50d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+-------------------+--------------------+\n",
      "| id|         latitude|          longitude|                geom|\n",
      "+---+-----------------+-------------------+--------------------+\n",
      "|  1|34.04378747880928|-118.30008569674712|POINT (-118.30008...|\n",
      "|  2|          20.5937|            78.9629|POINT (78.9629 20...|\n",
      "+---+-----------------+-------------------+--------------------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- geom: geometry (nullable = true)"
     ]
    }
   ],
   "source": [
    "# Create a geometry type from (Lat, Long) coordinate pairs\n",
    "data1 = [(1, 34.04378747880928, -118.30008569674712), (2, 20.5937, 78.9629)]\n",
    "schema1 = [\"id\", \"latitude\", \"longitude\"]\n",
    "df1 = spark.createDataFrame(data1, schema1)\n",
    "df1 = df1.withColumn(\"geom\", ST_Point(\"longitude\", \"latitude\"))\n",
    "df1.show()\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b4ec84-633a-40ce-9ca5-55186a8b2aa6",
   "metadata": {},
   "source": [
    "## Distance calculation using `ST_DistanceSphere`\n",
    "The following code implements the calculation of distance between two points, given their coordinates and taking into consideratin the spherical shape of the earth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cfef3d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+----------+--------------------+--------------------+-----------------+\n",
      "|latitude1|longitude1|latitude2|longitude2|              point1|              point2|      distance_km|\n",
      "+---------+----------+---------+----------+--------------------+--------------------+-----------------+\n",
      "|  12.9716|   77.5946|  20.5937|   78.9629|POINT (77.5946 12...|POINT (78.9629 20...|859.9436399522059|\n",
      "+---------+----------+---------+----------+--------------------+--------------------+-----------------+\n",
      "\n",
      "root\n",
      " |-- latitude1: double (nullable = true)\n",
      " |-- longitude1: double (nullable = true)\n",
      " |-- latitude2: double (nullable = true)\n",
      " |-- longitude2: double (nullable = true)\n",
      " |-- point1: geometry (nullable = true)\n",
      " |-- point2: geometry (nullable = true)\n",
      " |-- distance_km: double (nullable = true)"
     ]
    }
   ],
   "source": [
    "# Calculate distance\n",
    "data2 = [(12.9716, 77.5946, 20.5937, 78.9629)]\n",
    "schema2 = [\"latitude1\", \"longitude1\", \"latitude2\", \"longitude2\"]\n",
    "df2 = spark.createDataFrame(data2, schema2)\n",
    "df2 = df2.withColumn(\"point1\", ST_Point(\"longitude1\", \"latitude1\")).withColumn(\"point2\", ST_Point(\"longitude2\", \"latitude2\"))\n",
    "df2 = df2.withColumn(\"distance_km\", ST_DistanceSphere(\"point1\", \"point2\")/1000) # divide with 1000 to conver into km\n",
    "df2.show()\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a962ea56-43b0-4a32-a885-24c63efc18ff",
   "metadata": {},
   "source": [
    "## Join two DataFrames on inclusion condition using `ST_Within`\n",
    "This is how you can perform a join between two DataFrames that contain `geometry` type columns.\n",
    "\n",
    "The join condition here is whether the `geometry` defined in `df1.geom` is contained within `flattened_df.geometry`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56591532",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- geom: geometry (nullable = true)\n",
      " |-- BG10: string (nullable = true)\n",
      " |-- BG10FIP10: string (nullable = true)\n",
      " |-- BG12: string (nullable = true)\n",
      " |-- CB10: string (nullable = true)\n",
      " |-- CEN_FIP13: string (nullable = true)\n",
      " |-- CITY: string (nullable = true)\n",
      " |-- CITYCOM: string (nullable = true)\n",
      " |-- COMM: string (nullable = true)\n",
      " |-- CT10: string (nullable = true)\n",
      " |-- CT12: string (nullable = true)\n",
      " |-- CTCB10: string (nullable = true)\n",
      " |-- HD_2012: long (nullable = true)\n",
      " |-- HD_NAME: string (nullable = true)\n",
      " |-- HOUSING10: long (nullable = true)\n",
      " |-- LA_FIP10: string (nullable = true)\n",
      " |-- OBJECTID: long (nullable = true)\n",
      " |-- POP_2010: long (nullable = true)\n",
      " |-- PUMA10: string (nullable = true)\n",
      " |-- SPA_2012: long (nullable = true)\n",
      " |-- SPA_NAME: string (nullable = true)\n",
      " |-- SUP_DIST: string (nullable = true)\n",
      " |-- SUP_LABEL: string (nullable = true)\n",
      " |-- ShapeSTArea: double (nullable = true)\n",
      " |-- ShapeSTLength: double (nullable = true)\n",
      " |-- ZCTA10: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)"
     ]
    }
   ],
   "source": [
    "joined_df = df1 \\\n",
    "    .join(flattened_df, ST_Within(df1.geom, flattened_df.geometry), \"inner\")\n",
    "joined_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e2ce40-4de4-4ac3-a0b7-6cd2ada38e84",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Aggregate `geometry` columns using `ST_Union_Aggr`\n",
    "It is possible to aggregate areas defined by the `geometry` type using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a299ff8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- COMM: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)"
     ]
    }
   ],
   "source": [
    "LA_areas = flattened_df.filter(col(\"CITY\") == \"Los Angeles\") \\\n",
    "                .groupBy(\"COMM\") \\\n",
    "                .agg(ST_Union_Aggr(\"geometry\").alias(\"geometry\"))\n",
    "LA_areas.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "660c3a64-5231-40bb-b09b-d0d93a615e3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139"
     ]
    }
   ],
   "source": [
    "LA_areas.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
